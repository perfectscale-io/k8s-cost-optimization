{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kubernetes Cost Optimization Welcome to the Kubernetes Cost Optimization Guide This website provides the learning materials for engineers wishing to optimize their K8s cluster costs without compromizing performance and reliability. If you find issues with any of the website materials - please send us a note. Browse our guides: The Golden Signals of Kubernetes Cost Optimization The Economics of Kubernetes Resource Allocation The 4 Areas of Kubernetes Cost Optimization Balancing Cost with Performance and Reliability Kubernetes Workload Rightsizing Pod Autoscaling Cluster Autoscaling Leveraging Cloud Discounts","title":"Home"},{"location":"#kubernetes-cost-optimization","text":"","title":"Kubernetes Cost Optimization"},{"location":"#welcome-to-the-kubernetes-cost-optimization-guide","text":"This website provides the learning materials for engineers wishing to optimize their K8s cluster costs without compromizing performance and reliability. If you find issues with any of the website materials - please send us a note. Browse our guides: The Golden Signals of Kubernetes Cost Optimization The Economics of Kubernetes Resource Allocation The 4 Areas of Kubernetes Cost Optimization Balancing Cost with Performance and Reliability Kubernetes Workload Rightsizing Pod Autoscaling Cluster Autoscaling Leveraging Cloud Discounts","title":"Welcome to the Kubernetes Cost Optimization Guide"},{"location":"cloud-discounts/","text":"Leveraging Cloud Discounts Spot VMs and Best Effort Pods Combining Spot and On-Demand Fleets Applying Saving Plans to your Kubernetes clusters","title":"Leveraging Cloud Discounts"},{"location":"cloud-discounts/#leveraging-cloud-discounts","text":"Spot VMs and Best Effort Pods Combining Spot and On-Demand Fleets Applying Saving Plans to your Kubernetes clusters","title":"Leveraging Cloud Discounts"},{"location":"cluster-autoscaling/","text":"Cluster Autoscaling Cluster-autoscaler Karpenter Improving Kubernetes Bin Packing","title":"Cluster Autoscaling"},{"location":"cluster-autoscaling/#cluster-autoscaling","text":"Cluster-autoscaler Karpenter Improving Kubernetes Bin Packing","title":"Cluster Autoscaling"},{"location":"cost-perf-r9y/","text":"Balancing Cost with Performance and Reliability Kubernetes cost optimization comes down to pinpointing the correct resource allocations and auto-scaling factors for our workloads. But \"correct\" in this context doesn't mean \"the least possible amount of resources\". It's a delicate interplay of cost vs. performance vs.reliability. In order to run our clusters in the most cost-effective way without compromising either performance or reliability it's vitally inportant to understand the Pod QoS model and the implications of PodDisruptionBudget. Understanding the Pod QoS Model Kubernetes cost optimization starts with correct resource allocation for application containers that Kubernetes orchestrates. Each container can have requests and limits defined for either memory or cpu or both. PodDisruptionBudget and application disruption","title":"Balancing Cost with Performance and Reliability"},{"location":"cost-perf-r9y/#balancing-cost-with-performance-and-reliability","text":"Kubernetes cost optimization comes down to pinpointing the correct resource allocations and auto-scaling factors for our workloads. But \"correct\" in this context doesn't mean \"the least possible amount of resources\". It's a delicate interplay of cost vs. performance vs.reliability. In order to run our clusters in the most cost-effective way without compromising either performance or reliability it's vitally inportant to understand the Pod QoS model and the implications of PodDisruptionBudget.","title":"Balancing Cost with Performance and Reliability"},{"location":"cost-perf-r9y/#understanding-the-pod-qos-model","text":"Kubernetes cost optimization starts with correct resource allocation for application containers that Kubernetes orchestrates. Each container can have requests and limits defined for either memory or cpu or both. PodDisruptionBudget and application disruption","title":"Understanding the Pod QoS Model"},{"location":"golden-signals/","text":"The Golden Signals The 4 \"golden signals\" of Kubernetes Cost Optimization as defined in a whitepaper released by Google Cloud in June 2023. Signal Group 1.Workload Rightsizing Resources 2.Demand-based Downscaling 3.Cluster Bin Packing 4.Cloud Provider Discount Coverage Cloud Discounts These signals help us apply and measure cost optimization for Kubernets clusters. The 3 signals in the resources group apply to all clusters - be it on-prem or on-cloud. The cloud discounts naturally only apply to cloud-based managed clusters, where it is very important to pinpoint the instance types and reservation level of our cluster nodes. Let's explain each signal in a bit more detail. The Resources Group Signal Explanation Workload Rightsizing Refers to our ability to allocate the amount of resources that the workloads actually need and adapt resource requests and limits as application requirements change. Demand based autoscaling Measures the capacity of developers and platform admins to make clusters scale down during off-peak hours. Cluster bin packing Refers to our ability to measure and utilize the CPU and memory of each node in the most effective and reliable way through correct Pod placement. The Cloud Discounts group Signal Explanation Cloud Discount Coverage Refers to leveraging cloud VM instances that offer discounts, such as Spot VMs, as well as the ability of budget owners and FinOps professionals to take advantage of long-term continuous use discounts offered by cloud providers.","title":"The Golden Signals of Kubernetes Cost Optimization"},{"location":"golden-signals/#the-golden-signals","text":"The 4 \"golden signals\" of Kubernetes Cost Optimization as defined in a whitepaper released by Google Cloud in June 2023. Signal Group 1.Workload Rightsizing Resources 2.Demand-based Downscaling 3.Cluster Bin Packing 4.Cloud Provider Discount Coverage Cloud Discounts These signals help us apply and measure cost optimization for Kubernets clusters. The 3 signals in the resources group apply to all clusters - be it on-prem or on-cloud. The cloud discounts naturally only apply to cloud-based managed clusters, where it is very important to pinpoint the instance types and reservation level of our cluster nodes. Let's explain each signal in a bit more detail.","title":"The Golden Signals"},{"location":"golden-signals/#the-resources-group","text":"Signal Explanation Workload Rightsizing Refers to our ability to allocate the amount of resources that the workloads actually need and adapt resource requests and limits as application requirements change. Demand based autoscaling Measures the capacity of developers and platform admins to make clusters scale down during off-peak hours. Cluster bin packing Refers to our ability to measure and utilize the CPU and memory of each node in the most effective and reliable way through correct Pod placement.","title":"The Resources Group"},{"location":"golden-signals/#the-cloud-discounts-group","text":"Signal Explanation Cloud Discount Coverage Refers to leveraging cloud VM instances that offer discounts, such as Spot VMs, as well as the ability of budget owners and FinOps professionals to take advantage of long-term continuous use discounts offered by cloud providers.","title":"The Cloud Discounts group"},{"location":"hpa/","text":"HPA - The Horizontal Pod Autoscaler Horizontal Pod Autoscaler (HPA) in Kubernetes is a controller that automatically adjusts the number of pods based on observed CPU or memory utilization (default mode) or other metrics. The goal of HPA is to ensure that applications can handle varying loads efficiently by scaling out (increasing the number of pods) during high demand and scaling in (decreasing the number of pods) during low demand. This dynamic scaling helps maintain resource utilization and application performance. HPA continuously monitors the specified metrics and adjusts the replica count to match the desired state, ensuring that the application remains responsive. How HPA works HPA works as a control loop that runs at regular intervals. During each interval, the HPA controller queries the resource utilization metrics specified in the HPA configuration. The controller identifies the target resource defined by the scaleTargetRef field in the HPA configuration. It then selects the pods based on the target resource's selector labels and fetches the relevant metrics. For CPU and memory metrics, the controller uses the resource metrics API. For custom metrics, it uses the custom metrics API. If you want to create your own custom metrics adapter, take a look at the starter [template] (https://github.com/kubernetes-sigs/custom-metrics-apiserver) For metrics of individual pod resources, such as CPU usage, the HPA controller collects data for each pod that it targets. When a target utilization value is specified, the controller calculates the CPU utilization as a percentage of the resource request defined for each container within the pod. If any containers within a pod lack the necessary resource request settings, the CPU utilization for that pod will not be defined, and the autoscaler will not take any action based on the metric. HPA generally retrieves metrics from aggregated APIs like metrics.k8s.io , custom.metrics.k8s.io , or external.metrics.k8s.io . The metrics.k8s.io API is generally provided by an add-on called Metrics Server, which must be deployed separately. The Horizontal Pod Autoscaler (HPA) uses a straightforward algorithm to adjust the number of pod replicas based on the ratio of current metric values to desired metric values. The core formula is: desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )] For example, if the current CPU usage is 300m and the target is 150m, the number of replicas will double because 300.0 / 150.0 = 2.0 . Conversely, if the current usage is 75m, the replicas will be halved because 75.0 / 150.0 = 0.5 . Kubernetes HPA Shortcomings - Cost and Performance Metric Constraints and Conflicts : HPA cannot be used with VPA when both are based on CPU or memory metrics. This is because VPA adjusts resource requests and limits, which can conflict with HPA's scaling decisions. This limitation can lead to suboptimal resource allocation, impacting both cost efficiency and performance. Limited Resource Consideration : HPA doesn't consider IOPS, network bandwidth, or storage usage in its scaling decisions. This oversight can lead to performance bottlenecks or outages if these resources become constrained, potentially resulting in poor user experience and increased operational costs to address these issues reactively. Granularity and Resource Waste : HPA scales at the pod level, which may not provide the fine-grained control needed for certain applications. This can result in over-scaling or under-scaling, impacting both application performance and resource utilization. Moreover, HPA doesn't address resource waste within the Kubernetes cluster, leaving administrators responsible for identifying and managing unused or over-provisioned resources at the container level. This can lead to inefficiencies and increased costs if not carefully monitored. Scaling Latency and Stability : HPA operates on a polling interval (default 15 seconds), introducing a delay between detecting a need for scaling and implementing the change. This latency can be problematic during sudden traffic spikes, potentially leading to temporary performance degradation. To compensate, administrators might set more aggressive scaling parameters, potentially increasing resource costs. Moreover, without proper cooldown periods, HPA can cause rapid scaling up and down, leading to instability or \"flapping\". Careful configuration of stabilization windows is necessary to ensure stable scaling behavior, adding to management complexity. Resource Utilization Fluctuations : HPA makes scaling decisions based on current resource utilization metrics, which can be challenging for workloads with high variability. This can lead to \"thrashing,\" where the system rapidly scales up and down in response to short-term fluctuations. Thrashing impacts both performance stability and cost efficiency, as each scaling operation consumes resources and can incur additional costs, especially in cloud environments. Sampling rate limitations : Kubernetes' default configuration can hinder HPA's effectiveness for applications with rapidly changing workloads. The default metric collection interval of 15 seconds may not provide sufficiently granular data for making timely scaling decisions in highly dynamic environments. This limitation can result in delayed responses to changing conditions, potentially leading to performance issues during traffic spikes and inefficient resource utilization during lulls. This coarse sampling might lead to over-provisioning as a safety measure, increasing overall resource costs. Lack of Predictive Scaling : HPA's reactive approach, which responds to current conditions rather than anticipates future needs, can be suboptimal for applications with predictable traffic patterns or scheduled events. This can lead to temporary performance degradation during regular traffic spikes and impact cost efficiency, as resources are not preemptively allocated for known high-traffic periods. Cold Start Inefficiency : When new pods are created in response to increased demand, they require time to become fully operational. This includes time for container image pulling, application startup, and potentially warming up caches or establishing connections. During this period, the newly created pods consume resources but may not yet be able to handle their full share of the workload. This can lead to temporary resource inefficiency and potential performance impact during the scaling process. During a cold start, you're essentially paying for resources that are not yet fully utilized, which can impact overall cost efficiency, especially in environments with frequent scaling events. Optimizing HPA for Cost and Performance: Right-size your pods : Right-sizing your pods is a critical step in optimizing HPA for both cost and performance. By carefully configuring your pods with appropriate resource requests and limits, you create a more accurate baseline for HPA to make scaling decisions. This precision prevents unnecessary scaling events, which can lead to wasted resources and increased costs. Implement pod disruption budgets : Implementing Pod Disruption Budgets (PDBs) is an essential strategy for maintaining application stability during scaling events, which directly impacts both performance and cost efficiency. PDBs ensure that a minimum number of pods remain available during voluntary disruptions, such as node drains or cluster upgrades. This guarantee of minimum availability prevents performance degradation during scaling operations, ensuring that your application continues to serve requests effectively. PDBs help avoid scenarios where excessive pod terminations might trigger unnecessary scale-up events, thus preventing wasteful resource allocation and associated costs. An example of a PDB: apiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: my-app-pdb spec: minAvailable: 2 selector: matchLabels: app: my-app Utilize custom metrics : Instead of relying solely on generic CPU and memory metrics, custom metrics allow you to scale based on application-specific indicators that truly reflect your workload's needs. This approach leads to more precise and effective scaling decisions, ensuring that you're allocating resources where they're most needed. By scaling based on metrics that directly correlate with your application's performance, you can maintain optimal user experience while avoiding overprovisioning helps in optimizing both performance and cost. Adjust HPA parameters : Adjusting HPA parameters, particularly scaleUpStabilizationWindowSeconds and scaleDownStabilizationWindowSeconds, is crucial for fine-tuning your autoscaling behavior. These parameters help reduce thrashing \u2013 rapid scaling up and down \u2013 which can negatively impact both performance and cost. By setting appropriate stabilization windows, you give your system time to stabilize after a scaling event before making new scaling decisions. This approach prevents unnecessary scaling operations, reducing the associated performance overhead and resource costs. behavior: scaleDown: stabilizationWindowSeconds: 300 policies: - type: Percent value: 100 periodSeconds: 15 Implement cluster autoscaling : Implementing cluster autoscaling in conjunction with HPA provides a more holistic approach to resource management, optimizing both performance and cost at the cluster level. While HPA ensures that your application has the right number of pods, cluster autoscaling ensures that your Kubernetes cluster has enough nodes to accommodate these pods. This synergy prevents scenarios where HPA decisions are constrained by cluster capacity, ensuring that your application can scale as needed for optimal performance. Cluster autoscaling allows you to efficiently utilize cloud resources, scaling your infrastructure up or down based on actual demand, thus avoiding the costs associated with over-provisioned clusters. Consider alternative solutions : Considering alternative solutions like the Kubernetes Event-Driven Autoscaler (KEDA) or custom autoscaling solutions can provide more granular control and predictive scaling capabilities for applications with complex requirements. These advanced solutions can optimize performance by reacting more quickly to changes in workload or even anticipating them. The ability to scale more precisely and proactively can lead to significant savings by ensuring that resources are allocated only when truly needed and in the right quantities.","title":"Horizontal Pod Autoscaling (HPA)"},{"location":"hpa/#hpa-the-horizontal-pod-autoscaler","text":"Horizontal Pod Autoscaler (HPA) in Kubernetes is a controller that automatically adjusts the number of pods based on observed CPU or memory utilization (default mode) or other metrics. The goal of HPA is to ensure that applications can handle varying loads efficiently by scaling out (increasing the number of pods) during high demand and scaling in (decreasing the number of pods) during low demand. This dynamic scaling helps maintain resource utilization and application performance. HPA continuously monitors the specified metrics and adjusts the replica count to match the desired state, ensuring that the application remains responsive.","title":"HPA - The Horizontal Pod Autoscaler"},{"location":"hpa/#how-hpa-works","text":"HPA works as a control loop that runs at regular intervals. During each interval, the HPA controller queries the resource utilization metrics specified in the HPA configuration. The controller identifies the target resource defined by the scaleTargetRef field in the HPA configuration. It then selects the pods based on the target resource's selector labels and fetches the relevant metrics. For CPU and memory metrics, the controller uses the resource metrics API. For custom metrics, it uses the custom metrics API. If you want to create your own custom metrics adapter, take a look at the starter [template] (https://github.com/kubernetes-sigs/custom-metrics-apiserver) For metrics of individual pod resources, such as CPU usage, the HPA controller collects data for each pod that it targets. When a target utilization value is specified, the controller calculates the CPU utilization as a percentage of the resource request defined for each container within the pod. If any containers within a pod lack the necessary resource request settings, the CPU utilization for that pod will not be defined, and the autoscaler will not take any action based on the metric. HPA generally retrieves metrics from aggregated APIs like metrics.k8s.io , custom.metrics.k8s.io , or external.metrics.k8s.io . The metrics.k8s.io API is generally provided by an add-on called Metrics Server, which must be deployed separately. The Horizontal Pod Autoscaler (HPA) uses a straightforward algorithm to adjust the number of pod replicas based on the ratio of current metric values to desired metric values. The core formula is: desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )] For example, if the current CPU usage is 300m and the target is 150m, the number of replicas will double because 300.0 / 150.0 = 2.0 . Conversely, if the current usage is 75m, the replicas will be halved because 75.0 / 150.0 = 0.5 .","title":"How HPA works"},{"location":"hpa/#kubernetes-hpa-shortcomings-cost-and-performance","text":"Metric Constraints and Conflicts : HPA cannot be used with VPA when both are based on CPU or memory metrics. This is because VPA adjusts resource requests and limits, which can conflict with HPA's scaling decisions. This limitation can lead to suboptimal resource allocation, impacting both cost efficiency and performance. Limited Resource Consideration : HPA doesn't consider IOPS, network bandwidth, or storage usage in its scaling decisions. This oversight can lead to performance bottlenecks or outages if these resources become constrained, potentially resulting in poor user experience and increased operational costs to address these issues reactively. Granularity and Resource Waste : HPA scales at the pod level, which may not provide the fine-grained control needed for certain applications. This can result in over-scaling or under-scaling, impacting both application performance and resource utilization. Moreover, HPA doesn't address resource waste within the Kubernetes cluster, leaving administrators responsible for identifying and managing unused or over-provisioned resources at the container level. This can lead to inefficiencies and increased costs if not carefully monitored. Scaling Latency and Stability : HPA operates on a polling interval (default 15 seconds), introducing a delay between detecting a need for scaling and implementing the change. This latency can be problematic during sudden traffic spikes, potentially leading to temporary performance degradation. To compensate, administrators might set more aggressive scaling parameters, potentially increasing resource costs. Moreover, without proper cooldown periods, HPA can cause rapid scaling up and down, leading to instability or \"flapping\". Careful configuration of stabilization windows is necessary to ensure stable scaling behavior, adding to management complexity. Resource Utilization Fluctuations : HPA makes scaling decisions based on current resource utilization metrics, which can be challenging for workloads with high variability. This can lead to \"thrashing,\" where the system rapidly scales up and down in response to short-term fluctuations. Thrashing impacts both performance stability and cost efficiency, as each scaling operation consumes resources and can incur additional costs, especially in cloud environments. Sampling rate limitations : Kubernetes' default configuration can hinder HPA's effectiveness for applications with rapidly changing workloads. The default metric collection interval of 15 seconds may not provide sufficiently granular data for making timely scaling decisions in highly dynamic environments. This limitation can result in delayed responses to changing conditions, potentially leading to performance issues during traffic spikes and inefficient resource utilization during lulls. This coarse sampling might lead to over-provisioning as a safety measure, increasing overall resource costs. Lack of Predictive Scaling : HPA's reactive approach, which responds to current conditions rather than anticipates future needs, can be suboptimal for applications with predictable traffic patterns or scheduled events. This can lead to temporary performance degradation during regular traffic spikes and impact cost efficiency, as resources are not preemptively allocated for known high-traffic periods. Cold Start Inefficiency : When new pods are created in response to increased demand, they require time to become fully operational. This includes time for container image pulling, application startup, and potentially warming up caches or establishing connections. During this period, the newly created pods consume resources but may not yet be able to handle their full share of the workload. This can lead to temporary resource inefficiency and potential performance impact during the scaling process. During a cold start, you're essentially paying for resources that are not yet fully utilized, which can impact overall cost efficiency, especially in environments with frequent scaling events.","title":"Kubernetes HPA Shortcomings - Cost and Performance"},{"location":"hpa/#optimizing-hpa-for-cost-and-performance","text":"Right-size your pods : Right-sizing your pods is a critical step in optimizing HPA for both cost and performance. By carefully configuring your pods with appropriate resource requests and limits, you create a more accurate baseline for HPA to make scaling decisions. This precision prevents unnecessary scaling events, which can lead to wasted resources and increased costs. Implement pod disruption budgets : Implementing Pod Disruption Budgets (PDBs) is an essential strategy for maintaining application stability during scaling events, which directly impacts both performance and cost efficiency. PDBs ensure that a minimum number of pods remain available during voluntary disruptions, such as node drains or cluster upgrades. This guarantee of minimum availability prevents performance degradation during scaling operations, ensuring that your application continues to serve requests effectively. PDBs help avoid scenarios where excessive pod terminations might trigger unnecessary scale-up events, thus preventing wasteful resource allocation and associated costs. An example of a PDB: apiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: my-app-pdb spec: minAvailable: 2 selector: matchLabels: app: my-app Utilize custom metrics : Instead of relying solely on generic CPU and memory metrics, custom metrics allow you to scale based on application-specific indicators that truly reflect your workload's needs. This approach leads to more precise and effective scaling decisions, ensuring that you're allocating resources where they're most needed. By scaling based on metrics that directly correlate with your application's performance, you can maintain optimal user experience while avoiding overprovisioning helps in optimizing both performance and cost. Adjust HPA parameters : Adjusting HPA parameters, particularly scaleUpStabilizationWindowSeconds and scaleDownStabilizationWindowSeconds, is crucial for fine-tuning your autoscaling behavior. These parameters help reduce thrashing \u2013 rapid scaling up and down \u2013 which can negatively impact both performance and cost. By setting appropriate stabilization windows, you give your system time to stabilize after a scaling event before making new scaling decisions. This approach prevents unnecessary scaling operations, reducing the associated performance overhead and resource costs. behavior: scaleDown: stabilizationWindowSeconds: 300 policies: - type: Percent value: 100 periodSeconds: 15 Implement cluster autoscaling : Implementing cluster autoscaling in conjunction with HPA provides a more holistic approach to resource management, optimizing both performance and cost at the cluster level. While HPA ensures that your application has the right number of pods, cluster autoscaling ensures that your Kubernetes cluster has enough nodes to accommodate these pods. This synergy prevents scenarios where HPA decisions are constrained by cluster capacity, ensuring that your application can scale as needed for optimal performance. Cluster autoscaling allows you to efficiently utilize cloud resources, scaling your infrastructure up or down based on actual demand, thus avoiding the costs associated with over-provisioned clusters. Consider alternative solutions : Considering alternative solutions like the Kubernetes Event-Driven Autoscaler (KEDA) or custom autoscaling solutions can provide more granular control and predictive scaling capabilities for applications with complex requirements. These advanced solutions can optimize performance by reacting more quickly to changes in workload or even anticipating them. The ability to scale more precisely and proactively can lead to significant savings by ensuring that resources are allocated only when truly needed and in the right quantities.","title":"Optimizing HPA for Cost and Performance:"},{"location":"over-under-idle-waste/","text":"The 4 Focus Areas When starting out with Kubernetes Cost Optimization it's important to understand what to focus on. Redundant costs come from 2 main sources: wasted resources and idle resources . Both of these are usually caused by over-provisioning , intentional or unintentional. On the other hand - thoughtless cost reduction activity can lead to under-provisioning , which causes performance and reliability issues. When optimizing our cluster costs we want to focus on all of these areas iteratively - in order to keep our clusters as cost-effective and performant as needed. Now let's explain each of these focus areas in more detail. Wasted Resources Wasted resources are the resources that have been allocated but not utilized. In most unoptimizaed clusters we're observing up to 50% of waste, which translates to thousands of dollars or euros monthly. This waste comes from over-provisioning the containers in our pods. Read on to understand the reasons and perils of over-provsioning. Idle Resources Kubernetes comes with a promise of automatic bin packing. I.e - it is supposed to fit the largest possible amount of pods on every node in the cluster. But this is again dependent on engineers correctly defining 1) resource requests and 2) node sizes. Even with smart and well-tuned autoscaling tools like Karpenter this doesn't always work and we find ourselves with nodes that are more than half empty - with resources that were neither requested nor utilized. All these are idle resources and taking care of reducing them is an important focus area of Kubernetes Cost Optimization. Overprovisioning Pinpointing the exact memory and CPU requests for our pods is hard - it requires observing the application behaviour under production load over a significant time period. Therefore most engineers prefer to err towards overprovisioning - i.e setting requests much higher than the application will ever use. This leads to a large amount of allocated but unutilized resources all across the cluster. Just imagine your cluster runs 200 pods and each of them requests 100Mb more memory than it actually uses. Altogether you'll have 20Gb of wasted RAM across the cluster. These resources will be provisioned, paid for, but never actually used. Underprovisioning Container underprovisioning in Kubernetes occurs when the resources allocated to containers are insufficient to meet the demands of the applications they run. This scenario can arise from: underestimating the resource needs of an application excessively aggressive optimization based on incomplete data not setting resource requests altogether - which gives us BestEffort QoS pods Underprovisioning can lead to several issues, including poor application performance, increased latency, and even outages as containers are killed on OOM or evicted because of resource exhaustion. This can be especially problematic in production environments where reliability and responsiveness are critical. Browse the rest of our guides to learm how to address each one of these focus areas in your Kubernetes cost optimization effort.","title":"The 4 Focus Areas of Kubernetes Cost Optimization"},{"location":"over-under-idle-waste/#the-4-focus-areas","text":"When starting out with Kubernetes Cost Optimization it's important to understand what to focus on. Redundant costs come from 2 main sources: wasted resources and idle resources . Both of these are usually caused by over-provisioning , intentional or unintentional. On the other hand - thoughtless cost reduction activity can lead to under-provisioning , which causes performance and reliability issues. When optimizing our cluster costs we want to focus on all of these areas iteratively - in order to keep our clusters as cost-effective and performant as needed. Now let's explain each of these focus areas in more detail.","title":"The 4 Focus Areas"},{"location":"over-under-idle-waste/#wasted-resources","text":"Wasted resources are the resources that have been allocated but not utilized. In most unoptimizaed clusters we're observing up to 50% of waste, which translates to thousands of dollars or euros monthly. This waste comes from over-provisioning the containers in our pods. Read on to understand the reasons and perils of over-provsioning.","title":"Wasted Resources"},{"location":"over-under-idle-waste/#idle-resources","text":"Kubernetes comes with a promise of automatic bin packing. I.e - it is supposed to fit the largest possible amount of pods on every node in the cluster. But this is again dependent on engineers correctly defining 1) resource requests and 2) node sizes. Even with smart and well-tuned autoscaling tools like Karpenter this doesn't always work and we find ourselves with nodes that are more than half empty - with resources that were neither requested nor utilized. All these are idle resources and taking care of reducing them is an important focus area of Kubernetes Cost Optimization.","title":"Idle Resources"},{"location":"over-under-idle-waste/#overprovisioning","text":"Pinpointing the exact memory and CPU requests for our pods is hard - it requires observing the application behaviour under production load over a significant time period. Therefore most engineers prefer to err towards overprovisioning - i.e setting requests much higher than the application will ever use. This leads to a large amount of allocated but unutilized resources all across the cluster. Just imagine your cluster runs 200 pods and each of them requests 100Mb more memory than it actually uses. Altogether you'll have 20Gb of wasted RAM across the cluster. These resources will be provisioned, paid for, but never actually used.","title":"Overprovisioning"},{"location":"over-under-idle-waste/#underprovisioning","text":"Container underprovisioning in Kubernetes occurs when the resources allocated to containers are insufficient to meet the demands of the applications they run. This scenario can arise from: underestimating the resource needs of an application excessively aggressive optimization based on incomplete data not setting resource requests altogether - which gives us BestEffort QoS pods Underprovisioning can lead to several issues, including poor application performance, increased latency, and even outages as containers are killed on OOM or evicted because of resource exhaustion. This can be especially problematic in production environments where reliability and responsiveness are critical. Browse the rest of our guides to learm how to address each one of these focus areas in your Kubernetes cost optimization effort.","title":"Underprovisioning"},{"location":"pod-autoscaling/","text":"Pod Autoscaling Autoscaling is a widely accepted practice in cloud computing which entails automatically adjusting the amount of computational resources based on load. Autoscaling automates resource management and as such has a significant impact on cluster costs. Well configured autoscaling can make your cluster lean, efficient and reliable. Badly configured autoscaling can generate waste and reduce availability. Kubernetes comes with add-ons that allow us to autoscale pods in 2 distinct ways: Horizontally By changing the number of pod replicas in a workload (Deployment, StatefulSet) Vertically By changing the amount of resources (CPU, memory) allocated to each individual pod in a workload. Horizontal Pod Autoscaling Horizontal pod autoscaling is enabled by the following add-ons: (Follow the links for autoscaling optimization recommendations) HPA KEDA Vertical Pod Autoscaling Horizontal pod autosscaling is enabled by the following add-ons: (Follow the links for autoscaling optimization recommendations) VPA Goldilocks","title":"Overview"},{"location":"pod-autoscaling/#pod-autoscaling","text":"Autoscaling is a widely accepted practice in cloud computing which entails automatically adjusting the amount of computational resources based on load. Autoscaling automates resource management and as such has a significant impact on cluster costs. Well configured autoscaling can make your cluster lean, efficient and reliable. Badly configured autoscaling can generate waste and reduce availability. Kubernetes comes with add-ons that allow us to autoscale pods in 2 distinct ways: Horizontally By changing the number of pod replicas in a workload (Deployment, StatefulSet) Vertically By changing the amount of resources (CPU, memory) allocated to each individual pod in a workload.","title":"Pod Autoscaling"},{"location":"pod-autoscaling/#horizontal-pod-autoscaling","text":"Horizontal pod autoscaling is enabled by the following add-ons: (Follow the links for autoscaling optimization recommendations) HPA KEDA","title":"Horizontal Pod Autoscaling"},{"location":"pod-autoscaling/#vertical-pod-autoscaling","text":"Horizontal pod autosscaling is enabled by the following add-ons: (Follow the links for autoscaling optimization recommendations) VPA Goldilocks","title":"Vertical Pod Autoscaling"},{"location":"resources/","text":"The Economics of Kubernetes Resource Allocation This whole guide talks a lot about resources which is a highly overloaded word in Kubernetes world. All the objects defined in Kubernetes API (such as Pod, Service, ConfigMap, etc) are also called resources . But we're not referring to them here. So in order to make things clearer let's define resources for the purpose of this guide. When we say resources - we actually mean CPU, GPU, memory, network and storage. In the pre-cloud world all these needed to be defined in advance. Ordering and provisioning these resources took weeks or even months. In cloud native environments (i.e Kubernetes) these resources are highly dynamic in nature and can be allocated and released on demand - just by issuing an API call. The process of allocating additional resources in such an automated manner is called autoscaling. This automation gives us a lot of power by prividing access to addtional resources when needed (aka just-in-time provisioning). And it also creates undesirable artifacts if not configured correctly such as: Wasted resources (when we allocate more than we actually need) Reliability issues (when provisioning doesn't work as expected) Unexpected costs (when we don't have good control over what and when gets provisioned) Resource Allocation in Kubernetes Kubernetes has different ways of allocating, limiting and provisioning resources for application containers. CPU and memory allocation On the very basic level - engineers can request CPU and memory for a container by defining its resource requests and limits in the Pod resource spec: apiVersion: v1 kind: Pod metadata: name: example spec: containers: - image: perfectscale.io/example name: example resources: requests: cpu: 1 memory: 500Mi limits: cpu: 1 memory: 500Mi Storage Resource Allocation In order to allocate storage Kubernetes allows us to use its PersistentVolume allocation mechanisms in conjunction with one of the multiple supported storage providers (e.g OpenEBS, Portworx, etc.) Network Resource Allocation Network resources aren't managed by Kubernetes itself but instead are delegated to one of the multiple CNI networking providers, which are reponsible for provisioning, allocating and retiring network interfaces and addresses. Continue here to get a better understanding of the 4 main focus areas of Kubernetes Cost Optimization .","title":"The Economics of Kubernetes Resource Allocation"},{"location":"resources/#the-economics-of-kubernetes-resource-allocation","text":"This whole guide talks a lot about resources which is a highly overloaded word in Kubernetes world. All the objects defined in Kubernetes API (such as Pod, Service, ConfigMap, etc) are also called resources . But we're not referring to them here. So in order to make things clearer let's define resources for the purpose of this guide. When we say resources - we actually mean CPU, GPU, memory, network and storage. In the pre-cloud world all these needed to be defined in advance. Ordering and provisioning these resources took weeks or even months. In cloud native environments (i.e Kubernetes) these resources are highly dynamic in nature and can be allocated and released on demand - just by issuing an API call. The process of allocating additional resources in such an automated manner is called autoscaling. This automation gives us a lot of power by prividing access to addtional resources when needed (aka just-in-time provisioning). And it also creates undesirable artifacts if not configured correctly such as: Wasted resources (when we allocate more than we actually need) Reliability issues (when provisioning doesn't work as expected) Unexpected costs (when we don't have good control over what and when gets provisioned)","title":"The Economics of Kubernetes Resource Allocation"},{"location":"resources/#resource-allocation-in-kubernetes","text":"Kubernetes has different ways of allocating, limiting and provisioning resources for application containers.","title":"Resource Allocation in Kubernetes"},{"location":"resources/#cpu-and-memory-allocation","text":"On the very basic level - engineers can request CPU and memory for a container by defining its resource requests and limits in the Pod resource spec: apiVersion: v1 kind: Pod metadata: name: example spec: containers: - image: perfectscale.io/example name: example resources: requests: cpu: 1 memory: 500Mi limits: cpu: 1 memory: 500Mi","title":"CPU and memory allocation"},{"location":"resources/#storage-resource-allocation","text":"In order to allocate storage Kubernetes allows us to use its PersistentVolume allocation mechanisms in conjunction with one of the multiple supported storage providers (e.g OpenEBS, Portworx, etc.)","title":"Storage Resource Allocation"},{"location":"resources/#network-resource-allocation","text":"Network resources aren't managed by Kubernetes itself but instead are delegated to one of the multiple CNI networking providers, which are reponsible for provisioning, allocating and retiring network interfaces and addresses. Continue here to get a better understanding of the 4 main focus areas of Kubernetes Cost Optimization .","title":"Network Resource Allocation"},{"location":"rightsizing/","text":"Kubernetes Workload Rightsizing Requests Memory CPU Limits Memory CPU Understanding CPU throttling Defining resource guardrails LimitRange NamespaceQuota","title":"Kubernetes Workload Rightsizing"},{"location":"rightsizing/#kubernetes-workload-rightsizing","text":"Requests Memory CPU Limits Memory CPU Understanding CPU throttling Defining resource guardrails LimitRange NamespaceQuota","title":"Kubernetes Workload Rightsizing"}]}